{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb4454a-2066-4df0-ab45-8edb61783c8b",
   "metadata": {},
   "source": [
    "# What is a Perceptron\n",
    "A perceptron is a building block of neural network. \n",
    "\n",
    "A single perceptron is capable to classify an input into two classes (Binary classifier i-e 0 / 1).\n",
    "![A perceptron looks like this.](./perceptron_node.png \"Perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c87fa-45cb-47ee-bf78-b9518ad262b4",
   "metadata": {},
   "source": [
    "## Different parts of a perceptron:\n",
    "\n",
    "1. Input features (X) from dataset.\n",
    "2. Weights (W), one for each input feature and a bias B.\n",
    "3. A Net input Function.\n",
    "4. Activation Function to normalize the values between (0 - 1).\n",
    "5. Output (0/1 or Yes/No or Dog/ Cat etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7e38c-c877-49e6-8174-7bcf043fcacd",
   "metadata": {},
   "source": [
    "## Sonar Dataset\n",
    "\n",
    "Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time. The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.\n",
    "\n",
    "The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder). The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8a98b402-8f2c-482e-a8cd-0624ab239787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "84e3c1ed-1008-4a02-b3f8-d7f01d968d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [i for i in range(1,61)]\n",
    "columns.append(\"label\")\n",
    "df = pd.read_csv(\"sonar.all-data\",delimiter = \",\",names = columns,header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "fe21a357-44f5-42fb-b343-60309d150c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1       2       3       4       5       6       7       8       9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       10  ...      52      53      54      55      56      57      58  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       59      60  label  \n",
       "0  0.0090  0.0032      R  \n",
       "1  0.0052  0.0044      R  \n",
       "2  0.0095  0.0078      R  \n",
       "3  0.0040  0.0117      R  \n",
       "4  0.0107  0.0094      R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d7f74-994a-4f2b-9365-466ca1b6fccc",
   "metadata": {},
   "source": [
    "Replacing R with 0 and M with 1 as our perceptron can only deal with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "baba7954-fd00-4828-bc3d-cde76abd9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].replace({'R': 0, 'M': 1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "56116ad1-2b87-4fd0-ba6b-d954a9c60fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[columns[:-1]], df[columns[-1]], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5896d18f-931a-45f8-a8f7-62da3b511850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1       2       3       4       5       6       7       8       9   \\\n",
       "28   0.0100  0.0275  0.0190  0.0371  0.0416  0.0201  0.0314  0.0651  0.1896   \n",
       "42   0.0211  0.0319  0.0415  0.0286  0.0121  0.0438  0.1299  0.1390  0.0695   \n",
       "79   0.0108  0.0086  0.0058  0.0460  0.0752  0.0887  0.1015  0.0494  0.0472   \n",
       "97   0.0491  0.0279  0.0592  0.1270  0.1772  0.1908  0.2217  0.0768  0.1246   \n",
       "142  0.0526  0.0563  0.1219  0.1206  0.0246  0.1022  0.0539  0.0439  0.2291   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "106  0.0331  0.0423  0.0474  0.0818  0.0835  0.0756  0.0374  0.0961  0.0548   \n",
       "14   0.0124  0.0433  0.0604  0.0449  0.0597  0.0355  0.0531  0.0343  0.1052   \n",
       "92   0.0260  0.0192  0.0254  0.0061  0.0352  0.0701  0.1263  0.1080  0.1523   \n",
       "179  0.0394  0.0420  0.0446  0.0551  0.0597  0.1416  0.0956  0.0802  0.1618   \n",
       "102  0.0587  0.1210  0.1268  0.1498  0.1436  0.0561  0.0832  0.0672  0.1372   \n",
       "\n",
       "         10  ...      51      52      53      54      55      56      57  \\\n",
       "28   0.2668  ...  0.0118  0.0088  0.0104  0.0036  0.0088  0.0047  0.0117   \n",
       "42   0.0568  ...  0.0053  0.0090  0.0042  0.0153  0.0106  0.0020  0.0105   \n",
       "79   0.0393  ...  0.0161  0.0029  0.0078  0.0114  0.0083  0.0058  0.0003   \n",
       "97   0.2028  ...  0.0268  0.0081  0.0129  0.0161  0.0063  0.0119  0.0194   \n",
       "142  0.1632  ...  0.0380  0.0339  0.0149  0.0335  0.0376  0.0174  0.0132   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "106  0.0193  ...  0.0133  0.0078  0.0174  0.0176  0.0038  0.0129  0.0066   \n",
       "14   0.2120  ...  0.0078  0.0083  0.0057  0.0174  0.0188  0.0054  0.0114   \n",
       "92   0.1630  ...  0.0132  0.0118  0.0120  0.0051  0.0070  0.0015  0.0035   \n",
       "179  0.2558  ...  0.0118  0.0146  0.0040  0.0114  0.0032  0.0062  0.0101   \n",
       "102  0.2352  ...  0.0215  0.0331  0.0111  0.0088  0.0158  0.0122  0.0038   \n",
       "\n",
       "         58      59      60  \n",
       "28   0.0020  0.0091  0.0058  \n",
       "42   0.0049  0.0070  0.0080  \n",
       "79   0.0023  0.0026  0.0027  \n",
       "97   0.0140  0.0332  0.0439  \n",
       "142  0.0103  0.0364  0.0208  \n",
       "..      ...     ...     ...  \n",
       "106  0.0044  0.0134  0.0092  \n",
       "14   0.0196  0.0147  0.0062  \n",
       "92   0.0008  0.0044  0.0077  \n",
       "179  0.0068  0.0053  0.0087  \n",
       "102  0.0101  0.0228  0.0124  \n",
       "\n",
       "[139 rows x 60 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "04124abc-bbbd-4125-b6c0-f04721bc5d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28     0\n",
       "42     0\n",
       "79     0\n",
       "97     1\n",
       "142    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "299e193f-9923-4c43-9669-f5213866481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13de9a2-4990-4ce3-932f-81410f56fca2",
   "metadata": {},
   "source": [
    "## Weights\n",
    "Let's initialize Weights for each input feature. We have 60 features so we need to define 60 wieghts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "dd5b3b8e-aa9b-41e4-aa24-880a0736d8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.rand(60,1)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178913b8-4890-4075-afd9-7b3a432bec48",
   "metadata": {},
   "source": [
    "## Bias\n",
    "Let's initialize Bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "167e32ae-6e5a-45ca-bd0a-e942ccc19bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534334143242565"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.rand()\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e82abf-4a22-4e6a-a090-a4c796e8e6b0",
   "metadata": {},
   "source": [
    "## Forward Pass\n",
    "Forward pass contains two steps:\n",
    "1. **Net Input Function:** where we multiply each feature x with it's corresponding weight w and then sum all of the resulting values to get a single value Z. \n",
    "2. **Activation Function:** Applying activaton funciton on Z.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf207ee-ca28-4dab-aaa2-113b0d70ead1",
   "metadata": {},
   "source": [
    "### Net Input Function\n",
    "We have to comput the Net Input Function for all the training samples.\n",
    "\n",
    "\n",
    "![Net input function.](./NIF.png \"Net input function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9d6b0683-fb48-4141-ade6-1440c8658097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 139)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.T\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9d6ecccb-4654-44f1-8b85-0d90553a1555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139,)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "58fd09a3-d035-436e-971e-1f84f33cee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfTrainSamples = X_train.shape[1]\n",
    "numOfFeatures = X_train.shape[0]\n",
    "Z = np.zeros(numOfTrainSamples)\n",
    "\n",
    "for i in range(numOfTrainSamples):\n",
    "    for j in range(numOfFeatures): \n",
    "        z = float(X_train[j][i] * W[j])\n",
    "        Z[i] = Z[i]+z\n",
    "    Z[i] = Z[i] + b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e1e866e1-f840-4a19-99af-d530fd86ffb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f5fbf00e-0a33-435a-b570-3e1ade618f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.80494534, 9.55415854, 7.55115147, 8.27610417, 9.81346468])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7468c0d-f8a0-42bb-8528-ab0da92439da",
   "metadata": {},
   "source": [
    "Same net input function can be computed in an optimized manner by using vectorized code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "773ec026-8e6a-4405-aee4-9a80d6e7f879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "01adc718-e282-4e7f-85d4-5fd9aaed08ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 139)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d6b4633f-91fa-48b4-85c2-2f257ca20283",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.dot(W.T,X_train,) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0cd9f08a-a6af-41aa-9bed-06bd4475e83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 139)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "61a26eb7-123c-4a1d-af04-5bfdc80be4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.80494534, 9.55415854, 7.55115147, 8.27610417, 9.81346468])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[0,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2771418-b3a3-4164-9e76-b1d1858d9e3f",
   "metadata": {},
   "source": [
    "### Activation Funciton\n",
    "We apply activation function to normalize the output values between 0 and 1.\n",
    "Most commonly used Activation Functions are:\n",
    "1. Sigmoid\n",
    "2. Relu\n",
    "3. Leaky Relu\n",
    "4. tanh and more\n",
    "\n",
    "We will use sigmoid for our example.\n",
    "\n",
    "\n",
    "![Sigmoid function.](./sigmoid.png \"Sigmoid Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "de62a42a-2f87-41fe-9a70-cfdcdbe72828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "654f5925-cde5-4b29-b6ac-56bccfc21a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [sigmoid(z) for z in Z[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2c5564b4-0047-4e4e-ab0e-6459e96745de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9995924524605656,\n",
       " 0.9999290992428377,\n",
       " 0.9994747713324592,\n",
       " 0.9997455379037005,\n",
       " 0.9999452930277559]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0104085-eb20-4939-a9ee-d3fe23ea2760",
   "metadata": {},
   "source": [
    "More optimized way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a5a050f8-395f-46e8-9672-43d6189120f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b9cd1c49-c643-4eb9-97ee-eafa1ba2e362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99959245, 0.9999291 , 0.99947477, 0.99974554, 0.99994529])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d8a4f-1a88-449a-a2df-564340f80edc",
   "metadata": {},
   "source": [
    "### What's Next?\n",
    "We have computed the output values, now what to do with them? We need the perceptron to answer in Rock / Mine or in other words 0 / 1.\n",
    "We need to apply a threshold on the output values. In most cases a threshold of 0.5 is used. All the output values greater than 0.5 will be considered as 1 and less than 0.5 will be considered as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "51f773cd-992b-48ee-ae9d-229858b069bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.where(A < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "411e6627-926e-4997-9aaa-ff1f15a17629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "caae408d-8769-43aa-ab86-e1f4a3080d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9885edc1-d53e-4023-ae2d-65ffe2af86fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139,)\n",
      "(1, 139)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9f7c6825-2fc6-4394-b722-78ebe67b335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.expand_dims(y_train,axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b0ace564-e220-4581-8c6c-c7147963958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 139)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd8736-a92b-4ae4-8046-b8f0b12f5bdf",
   "metadata": {},
   "source": [
    "## Output Analysis\n",
    "Our perceptron has not properly categorized the input. We have a lot of errors in it. Let's correct our perceptron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a6c86-e4ca-44f1-86ba-30764e097ea1",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "In Back propagation we compute errors / loss/ cost using a loss function and then tell each weight that how much it has contributed in the error which is done by taking partial derivative of Loss function with respect to each weight. \n",
    "\n",
    "### Error Functions:\n",
    "1. Mean Error Loss\n",
    "2. Mean Squared Error \n",
    "3. Mean Absolute Error\n",
    "4. Mean Squared Logarithmic Error Loss (MSLE)\n",
    "5. Mean Percentage Error\n",
    "6. Mean Absolute Percentage Error\n",
    "7. Binary Classification Losses Binary Cross Entropy\n",
    "8. Multi-Class Cross-Entropy\n",
    "9. Squared Hinge Loss\n",
    "10. Hinge Loss\n",
    "\n",
    "\n",
    "For our example we will be using Binary Cross Entropy Loss:\n",
    "![Binary cross entropy loss.](./loss.png \"Loss function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "bf66aa37-453c-4b2c-88ac-0df6397dd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(A, Y):\n",
    "    return -(Y * np.log(A) + (1 - Y) * np.log(1 - A)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1dec07dc-997a-4160-864e-434b963e6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-298-f812bb7d02b5>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  return -(Y * np.log(A) + (1 - Y) * np.log(1 - A)).mean()\n",
      "<ipython-input-298-f812bb7d02b5>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -(Y * np.log(A) + (1 - Y) * np.log(1 - A)).mean()\n"
     ]
    }
   ],
   "source": [
    "J = binary_cross_entropy(A, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb4eec-bc34-45a9-b407-bfcddd8b34a1",
   "metadata": {},
   "source": [
    "Our implementation of loss function cannot handle log of 0 which is equal to 1 ( log(0) = 1 ), that's why we will use library function for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "96b131f0-367e-4806-8329-d6feaf872834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "J = log_loss(y_train,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "00966af3-7603-41b8-b1ff-25df2b88f9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360.21659711854045"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bc681-e357-47e1-8c48-4050f17275ac",
   "metadata": {},
   "source": [
    "## Computing Gradients/ Slopes/ Derivatives\n",
    "Below are the partial derivatives of Loss function.\n",
    "\n",
    "![dz.](./dz.png \"dz\")\n",
    "\n",
    "![dw.](./dw.png \"dw\")\n",
    "\n",
    "![db.](./db.png \"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f887cb69-dec0-4a2c-8f13-3cba0d5f19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = A - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "221da50b-94d9-4de7-88d6-ae0a84616fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 139)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "8d9f7fbf-5e36-4566-ac83-b56525d51972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 139)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67de72f-71b7-4c3f-b5ae-476c5680aa8e",
   "metadata": {},
   "source": [
    "We need to compute derivative of each weight for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d4f40575-f3f4-4635-a99c-9b4fb5255f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = np.zeros(len(W))\n",
    "for i in range(len(W)):\n",
    "    for j in range(X_train.shape[1]):\n",
    "        #print(str(i)+ \" \"+ str(j))\n",
    "        #print(X_train[i][j])\n",
    "        dw[i] = dw[i] + dz[0][j]*X_train[i][j]\n",
    "    dw[i] = dw[i]/X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "3faad236-f236-485f-9d51-54479642da4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0104705 , 0.0154964 , 0.01788489, 0.02003237, 0.03098993])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f9aa0a0f-68c3-4eba-bb22-730c75e85663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfTrainSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f75fca-b55b-4e54-a39b-89dfcb400063",
   "metadata": {},
   "source": [
    "More optimized way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "81de314d-e6e3-4cd6-8516-3cedfc106292",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw =  np.dot(X_train,dz.T)/numOfTrainSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "98807932-c7b3-4301-afe9-d6e785883d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0104705 ],\n",
       "       [0.0154964 ],\n",
       "       [0.01788489],\n",
       "       [0.02003237],\n",
       "       [0.03098993]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e32224-3e72-408f-9b7b-b23ed7b6186a",
   "metadata": {},
   "source": [
    "For bias we need just need the mean of sum of all dz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1a1a524d-a517-462e-8dd1-5b03b193d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = np.sum(dz,axis =1)/numOfTrainSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758400c-73b4-4c22-987c-4c4242b13509",
   "metadata": {},
   "source": [
    "## Gradient Desent Step\n",
    "Now we will update all the weights according to their slopes.\n",
    "\n",
    "**Learning Rate (alpha)**\n",
    "alpha is used to control the gradients, if we keep the alpha too high our gradients will diverge from minimum and if we take the alpha too low, the gradients will converge to minimum slowly.\n",
    "\n",
    "alpha range [0,1]\n",
    "\n",
    "let's suppose alpha is 0.001\n",
    "\n",
    "### Update formulas for weight and bias\n",
    "\n",
    "![w_update.](./w_update.png \"w_update\")\n",
    "\n",
    "\n",
    "![b_update.](./b_update.png \"b_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "26bdd29a-d413-4d85-b526-f517722eb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "57d442b8-1700-4923-9e57-cdfe80c8c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W - alpha * dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "6cdf6512-285e-4bc4-ab03-e75e6b26c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b - alpha *db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878fd66-0493-40c1-9e11-9a04fbf861eb",
   "metadata": {},
   "source": [
    "## Epoch\n",
    "1 Forward and 1 Backward pass is known as 1 epoch.\n",
    "\n",
    "## Task\n",
    "1. Write code to perform N number of epochs until the loss gets close to zero.\n",
    "2. Compute the loss after each epcoh using sklearn loss function.\n",
    "3. Once the perceptron gets trained, test the trained perceptron on testing data and report test accuracy, confusion matrix.\n",
    "4. Try different values of alpha and see how it affects the training process.\n",
    "5. Use the above vectorized code to make 2 layer Neural Network. 1st layer will contain 2 Perceptrons and last layer will contain 1 perceptron. See how it affects the performance using accuracy and confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f1d41e12-72de-4851-a9bb-f5d1ab1d814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#farword pass\n",
    "for i in range(1,1000):\n",
    "    \n",
    "    Z=np.dot(W.T,X_train,)+b\n",
    "    A=sigmoid(Z)\n",
    "    A=np.where(A<0.5,0,1)\n",
    "\n",
    "\n",
    "    #backwork pass\n",
    "    J=log_loss(y_train,A)\n",
    "    dz=A-y_train\n",
    "    dw=np.dot(X_train,dz.T)/numOfTrainSamples\n",
    "    db =np.sum(dz,axis =1)/numOfTrainSamples\n",
    "    W=W-alpha*dw\n",
    "    b=b-alpha*db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ca2d55df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890.7576637987378\n"
     ]
    }
   ],
   "source": [
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "6c8256de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 69)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.T\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "7105c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding testing loss on testing data\n",
    "\n",
    "Z=np.dot(W.T,X_test,)+b\n",
    "A=sigmoid(Z)\n",
    "A=np.where(A<0.5,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e7ecb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.expand_dims(y_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c0200c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 69)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "349a5bc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-df9f98fb5681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 2]"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, X_test.shape)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c325dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296faa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
